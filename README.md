# Анализ вакансий Habr Career

## Обзор проекта

Данный проект представляет собой комплексное исследование рынка труда в IT-сфере на основе данных с платформы Habr Career. Проект включает в себя сбор, обработку, анализ и визуализацию данных о вакансиях, что позволяет выявить актуальные тренды и закономерности на рынке IT-специалистов.

## Структура репозитория

habr_work/
├── README.md                  # Описание проекта
├── requirements.txt           # Зависимости проекта
├── dashboard/                 # Директория с дашбордом
│   └── app.py                 # Дашборд на Streamlit
├── data/                      # Директория с данными
│   ├── processed/             # Обработанные данные
│   │   └── vacancies.csv      # CSV файл с вакансиями
│   └── raw/                   # Сырые данные
│       └── *.jsonl            # JSONL файлы с исходными данными
├── notebooks/                 # Jupyter ноутбуки
│   └── 01_EDA(1).ipynb        # Ноутбук с анализом данных
└── scripts/                   # Скрипты для сбора и обработки данных
├── collect_habr.py        # Скрипт сбора данных
└── clean_habr.py          # Скрипт очистки данных


## Этапы проекта

### 1. Сбор данных

В рамках проекта реализован механизм сбора данных с веб-сайта [Habr Career](https://career.habr.com/). Скрипт `collect_habr.py` осуществляет парсинг страниц с вакансиями и извлекает следующую информацию:

- Заголовок вакансии
- Компания
- Город
- Формат работы (удаленный/офисный)
- Дата публикации
- Зарплатные ожидания
- Требуемые навыки
- Детальное описание вакансии (при включении опции `--detailed`)

### 2. Очистка и подготовка данных

После сбора данных выполняется их очистка и обработка с помощью скрипта `clean_habr.py`. На этом этапе происходит:

- Нормализация текстовых полей
- Приведение дат к стандартному формату
- Конвертация зарплат в единую валюту (рубли)
- Извлечение дополнительных признаков из текстовых описаний
- Категоризация данных по различным параметрам

### 3. Анализ и визуализация

Анализ данных выполняется в Jupyter ноутбуке и представлен в виде интерактивного дашборда на базе Streamlit. Дашборд позволяет:

- Исследовать распределение вакансий по городам, компаниям и форматам работы
- Анализировать зарплатные предложения в различных срезах
- Выявлять наиболее востребованные навыки на рынке труда
- Определять корреляции между различными параметрами вакансий

### 4. Результаты и выводы

Основные выводы исследования:

- Выявлена географическая концентрация вакансий в крупных городах
- Установлена значительная доля удаленных вакансий, отражающая трансформацию рынка труда
- Определена иерархическая структура навыков с доминированием Python и SQL
- Обнаружена экономическая стратификация зарплатных предложений

## Инструкция по запуску

### Требования

Для запуска проекта необходимо установить зависимости из файла requirements.txt:


pip install -r requirements.txt

Сбор данных


# Базовый сбор вакансий
python scripts/collect_habr.py --pages 50 --query "python"

# Сбор с детальной информацией
python scripts/collect_habr.py --pages 30 --query "data science" --detailed

Обработка данных

# Базовая обработка
python scripts/clean_habr.py

# С выводом EDA-статистики
python scripts/clean_habr.py --eda


Запуск дашборда


# Из корня проекта
streamlit run dashboard/app.py

# Или из директории dashboard
cd dashboard
streamlit run app.py

